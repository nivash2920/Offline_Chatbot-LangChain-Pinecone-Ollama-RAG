<h1>RAG-based Chatbot with LangChain, Ollama, and Pinecone</h1>

<h2>Project Overview</h2>
<p>Built an AI-powered chatbot with Streamlit UI, integrating Ollama LLM for natural language conversations.</p>
<p>Implemented retrieval-augmented generation (RAG) by connecting LangChain with Pinecone vector database for semantic document search.</p>
<p>Processed and indexed PDFs using a custom text-splitting + embedding pipeline with mxbai-embed-large.</p>
<p>Designed system prompts for concise and context-aware responses.</p>
<p>Enabled end-to-end document ingestion, similarity retrieval, and real-time Q&A deployment.</p>

<h2>üõ†Ô∏è Skills Demonstrated</h2>
<ul>
    <li><strong>Generative AI:</strong> Building RAG (Retrieval-Augmented Generation) pipelines</li>
    <li><strong>LLM Integration:</strong> Working with Ollama, LLaMA models, and LangChain for custom embeddings & chat flows</li>
    <li><strong>Vector Databases:</strong> Experience with Pinecone for similarity search and semantic retrieval</li>
    <li><strong>Embeddings:</strong> Creating and using embeddings with Ollama embeddings (mxbai-embed-large) and integrating with vector stores</li>
    <li><strong>Document Processing:</strong> Loading and chunking PDFs using LangChain loaders and text splitters</li>
    <li><strong>Application Development:</strong> Deploying AI-powered chatbots with Streamlit</li>
    <li><strong>Prompt Engineering:</strong> Designing system prompts for context-aware question answering</li>
    <li><strong>Environment Management:</strong> Using .env files and dotenv for secure API handling</li>
    <li><strong>APIs & Integration:</strong> Experience working with external APIs (Pinecone, Ollama)</li>
    <li><strong>Python Development:</strong> Writing modular, production-ready Python code for AI workflows</li>
</ul>

<h2>Installation & Setup</h2>
<ol>
    <li>
        Clone the repository:
        <pre>
git clone https://github.com/nivash2920/Offline_Chatbot-LangChain-Pinecone-Ollama-RAG.git
    </li>
</ol>
